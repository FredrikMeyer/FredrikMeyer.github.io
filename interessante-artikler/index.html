---
layout: page
status: publish
published: true
title: Interessante artikler
author: Fredrik Meyer
author_login: fredrikmeyer
author_email: hrmeyer@gmail.com
wordpress_id: 148
wordpress_url: http://fredrikmeyer.net/?page_id=148
date: '2017-06-06 22:33:16 +0200'
date_gmt: '2017-06-06 20:33:16 +0200'
categories: []
tags: []
comments: []
---
<h2>Matematikk</h2>
<ul>
<li><a href="https://arxiv.org/abs/1706.03346">Machine Learning of Calabi-Yau volumes</a>. Morsom liten sak. Forfatterne bruker nevralnettverk til &aring; regne ut volum til basen til visse ikke-kompakte toriske varieteter. N&aring; kan jeg ikke s&aring; mye om maskinl&aelig;ring, men for meg virker det rart at de forkaster $GL(2,\mathbb Z)$-ekvivalente diagrammer (mer treningsdata, right?). I tillegg er jeg usikker p&aring; om deres begrunnelse for &aring; bruke CNNs (convolutional neural networks) er riktig. De sier de gj&oslash;r dette siden diagrammet er representert neste som et bilde, men de glemmer &aring; nevne at det viktige i de toriske diagrammene er randen (de har tomt interi&oslash;r), og CNNs er veldig god p&aring; &aring; gjenkjenne data som er like viktig p&aring; <em>hele&nbsp;</em>input-matrisen.
<p>Det er morsomt &aring; se maskinl&aelig;ring bli brukt ogs&aring; i teoretisk fysikk og matematikk. Det blir spennende &aring; se om de faktisk kan brukes til &aring; bevise ting i framtiden. Senest i g&aring;r s&aring; jeg <a href="https://arxiv.org/abs/1706.02714">denne artikkelen</a>, om &aring; bruke maskinl&aelig;ring til &aring; kartlegge Calabi-Yau-landskapet. (13/6-17)</li>
</ul>
<h2>Programmering</h2>
<ul>
<li><a href="http://sijinjoseph.com/programmer-competency-matrix/">"Programming Competency Matrix".</a></li>
</ul>
